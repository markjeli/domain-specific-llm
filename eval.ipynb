{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "from peft import PeftModel, PeftModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"meta-llama/Llama-3.2-1B\"\n",
    "# model_name_or_path = \"Llama-3.2-1B-abstract\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    device_map=device,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"meta-llama/Llama-3.2-1B\"\n",
    "peft_model_id = \"Llama-3.2-1B-abstract-4bit\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token = \"<|finetune_right_pad_id|>\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map=device, quantization_config=quantization_config\n",
    ")\n",
    "model = PeftModelForCausalLM.from_pretrained(model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ans0</th>\n",
       "      <th>ans1</th>\n",
       "      <th>ans2</th>\n",
       "      <th>ans3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the gold standard method for detecting...</td>\n",
       "      <td>ELISA</td>\n",
       "      <td>RT-PCR</td>\n",
       "      <td>Western</td>\n",
       "      <td>Flowcytometry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which neurotransmitter system is primarily ass...</td>\n",
       "      <td>Dopaminergic</td>\n",
       "      <td>Serotonergic</td>\n",
       "      <td>Opioid</td>\n",
       "      <td>Cholinergic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the primary embryonic origin of microg...</td>\n",
       "      <td>Liver</td>\n",
       "      <td>Yolk Sac</td>\n",
       "      <td>Bone Marrow</td>\n",
       "      <td>Thymus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which pediatric vasculitis is classically asso...</td>\n",
       "      <td>Kawasaki</td>\n",
       "      <td>Takayasu</td>\n",
       "      <td>Behçet</td>\n",
       "      <td>Sarcoidosis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which immune cell type is primarily responsibl...</td>\n",
       "      <td>Bcells</td>\n",
       "      <td>CD4</td>\n",
       "      <td>CD8</td>\n",
       "      <td>NKcells</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question          ans0  \\\n",
       "0  What is the gold standard method for detecting...         ELISA   \n",
       "1  Which neurotransmitter system is primarily ass...  Dopaminergic   \n",
       "2  What is the primary embryonic origin of microg...         Liver   \n",
       "3  Which pediatric vasculitis is classically asso...      Kawasaki   \n",
       "4  Which immune cell type is primarily responsibl...        Bcells   \n",
       "\n",
       "           ans1         ans2           ans3  label  \n",
       "0        RT-PCR      Western  Flowcytometry      1  \n",
       "1  Serotonergic       Opioid    Cholinergic      2  \n",
       "2      Yolk Sac  Bone Marrow         Thymus      1  \n",
       "3      Takayasu       Behçet    Sarcoidosis      0  \n",
       "4           CD4          CD8        NKcells      2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"simple_med_eval.csv\")\n",
    "correct_ans_mapping = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\"\n",
    "}\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_idx = 0\n",
    "question = df.iloc[question_idx][\"question\"]\n",
    "ans0 = df.iloc[question_idx][\"ans0\"]\n",
    "ans1 = df.iloc[question_idx][\"ans1\"]\n",
    "ans2 = df.iloc[question_idx][\"ans2\"]\n",
    "ans3 = df.iloc[question_idx][\"ans3\"]\n",
    "correct_ans = df.iloc[question_idx][\"label\"]\n",
    "prompt = f\"\"\"\n",
    "Medicine and Health\n",
    "Multiple choice questions\n",
    "Solution set:\n",
    "Question: Which type of model does the DUST framework use for virtual staining in histopathology?\n",
    "A: GANs\n",
    "B: Diffusion\n",
    "C: Transformers\n",
    "D: CNNs\n",
    "Answer: B\n",
    "Question: Which organization provides national-level hospital accreditation in India?\n",
    "A: WHO\n",
    "B: KASH\n",
    "C: NABH\n",
    "D: CDC\n",
    "Answer: C\n",
    "Question: {question}\n",
    "A: {ans0}\n",
    "B: {ans1}\n",
    "C: {ans2}\n",
    "D: {ans3}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "Medicine and Health\n",
      "Multiple choice questions\n",
      "Solution set:\n",
      "Question: Which type of model does the DUST framework use for virtual staining in histopathology?\n",
      "A: GANs\n",
      "B: Diffusion\n",
      "C: Transformers\n",
      "D: CNNs\n",
      "Answer: B\n",
      "Question: Which organization provides national-level hospital accreditation in India?\n",
      "A: WHO\n",
      "B: KASH\n",
      "C: NABH\n",
      "D: CDC\n",
      "Answer: C\n",
      "Question: What is the gold standard method for detecting SARS-CoV-2 in clinical samples?\n",
      "A: ELISA\n",
      "B: RT-PCR\n",
      "C: Western\n",
      "D: Flowcytometry\n",
      "Answer: B\n",
      "Question: Which of the following is the most common cause\n",
      "--------------------\n",
      "Correct Answer: B\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(f\"Response: {response[len(prompt):]}\")\n",
    "print(f\"Response: {response}\")\n",
    "print(\"--------------------\")\n",
    "print(f\"Correct Answer: {correct_ans_mapping[correct_ans]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
